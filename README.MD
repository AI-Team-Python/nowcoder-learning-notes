# 学习计划

## C++ 学习

C++多态性是如何理解

## Leecode 刷题

## 机器学习

python

### 基础

- 周志华的《机器学习》（俗称的西瓜书）
- 李航老师的《统计学习方法》
- 《机器学习实战》和《集体智慧编程》


### 熟悉 tensorflow 


### 其他（暂时葫忽略）

Mapreduce原理，Linux物理内存分配 ，红黑树的应用场景 ，有一百个用户同时买一件商品，如何保证请求的顺序性 

## 确定方向

### 方向：NLP

- 文本分类
- 分词
- 标注
- 信息抽取
- 词性标注
- 实体标注
- lstm


### 看论文

实战实战实战实战！！！！！！！！！！！！！！！！！！


## 参加比赛


参加一些比赛，比如kaggle,天池，滴滴的一些比赛



## 别人的面经

1. 百度

项目经验

rcnn,fast-rcnn,faster-rnn,yolo,ssd

调参，正则化，Batch normalization,drop out,激活函数的选择。手动推导BP,LR,SVM

算法题主要有常规的排序，二分查找，BP相关的题目，还有一些就是关于二叉树的递归和非递归遍历，层次遍历，最近公共祖先等

LR和SVM区别 

手写快排 

L1正则化和l2正则化 解释 推导 联系和区别

基础的机器学习的方法 lr 推导loss函数 推导sgd的参数更新结果 lr和svm的区别 

手写二叉树的层序遍历 循环实现和递归实现 

随机森林的原理 bagging和boosting的联系和区别 adaboost跟随机森林的区别 

2. 阿里

自我介绍，对你影响最大的项目，这个项目中你的收获，算法题
     一个有障碍的100*100的地图，求最短路径。判断一个坐标点是否在不规则多边形内部。 

快排，KMP算法，二叉树

前序遍历二叉树，哈希表、

排序方法有哪些，哪些效率比较高，如果是排序好的用什么排序方式，如果数组会溢出，用什么排序方式。快排为什么效果好

极大似然算法原理，EM算法为什么收敛、原理。

CGBOOST为什么比GBDT效果好，梯度提升树是啥意思。

朴素贝叶斯假设，解释贝叶斯公式。 

机器学习代价函数

随机森林原理，从偏差和方差的角度考虑

二叉树合并，前缀树定义，基本操作，代码

（1）写代码，在有限的字符串中，寻找没有重复的最长子字符串

（2）LR为什么用对数代价函数。除了随机梯度下降还能用什么算法解

（3）XGBOOST用什么代价函数

（4）随机森林过程，为什么比SVM效果好

（1）L1范数和L2范数，回归问题的时候怎么选择

（2）怎么提高召回率

（3）随机森林做特征工程有什么优势

（4）聚类中怎么判断k是合适的，分类好了怎么描述各个类

（5）正负样本不均衡怎么解决的

（6）在sklearn中怎么实现后剪枝

（7）神经网络的激活函数


3. 瓜子二手车

    （1）代价函数有哪些

    （2）数字个数较少时，用什么排序方法

    （3）写代码，旋转数组中查找某个值

    （4）GBDT梯度下降原理

    （5）随机森林

    （6）聚类如果只知道样本互相之间的距离，如何选择聚类中心点

    （7）贝叶斯公式，连续离散

    （8）掷骰子 得到五分之一的概率
        是近似的思想，因为不管怎么掷分母都不会出现5，所以只能是概率与1/5的差小于某个值，面试官还会问，如果差值为多少了，那还需要迭代多少次。

    （9）L1 和L2范数的区别

    （10）连续特征怎么处理

    （11）LR模型推导

    （12）神经网络

    （13）给定结点数，有多少中二叉树结构

4. 其他

BP神经网络。反向传播的细节等。

一道具体场景题目，怎么使用机器学习的技术解决这个问题。 

讨论了KNN。讨论有关维度爆炸的问题。 

讨论了SVM。SVM的推倒，原理，最优化方法。为何SVM可以解决分类问题。 

LR的详细讨论，正则化问题，调参方法

LR的讨论，SVM的推导，手写代码：第一个是关于二叉树的遍历，不能用栈，不能递归。第二个是链表本地倒置。然后讨论了地图算法相关的问题。 

LR的损失函数，推导，优缺点，正则化的作用

LR为什么用sigmoid函数。这个函数有什么优点和缺点？为什么不用其他函数？

SVM原问题和对偶问题关系？KKT条件用哪些，完整描述

有一堆已经分好的词，如何去发现新的词？
     面试官给的提示：用这个词和左右词的关系。互信息 新词的左右比较丰富，有的老词的左右也比较丰富。还要区分出新词和老词。 

L1正则为什么可以把系数压缩成0，坐标下降法的具体实现细节

说一下进程和线程

数据库中主键、索引和外键。以及作用
    一个表可以没有主键，可以有索引 

SVM原理，拉格朗日法，对偶问题，以及好处。

SVM怎么防止过拟合：说了SVM里面的松弛变量。不知道对不对


项目延展题：电商搜索框，每天有500W的搜索query。针对新来的一个query，给出和它最相似的100个query。

    如果用RNN分类模型表征，那么向量不应该用最后一层的分类特征。应该用倒数第二层的更纯的特征。
    现在假设500W的query已经是向量了。如何和这一个query比较。全部算距离不行，开销太大。 

K-means聚类个数选择，做什么样的试验来确定K 

两个4G的文件（每个文件可能有重复），里面全都是数字。现有内存1G，求这两个文件的交集。

    2个4G的文件，分别hash成10个子文件，一个400M。
    把一个子文件存储到hash表中，作为key。遍历另一个文件，看这个数字是否存在于刚才的hash表中。存在即可输出。 

作者：crazyhoney
链接：https://www.nowcoder.com/discuss/32008?type=2&order=0&pos=40&page=3
来源：牛客网

、自我介绍

2、介绍项目

3、说了SVM

4、为什么要把原问题转换为对偶问题？

因为原问题是凸二次规划问题，转换为对偶问题更加高效。

5、为什么求解对偶问题更加高效？

我答了，因为只用求解alpha系数，而alpha系数只有支持向量才非0，其他全部为0.

6、alpha系数有多少个？

我答了：样本点的个数

7、避免过拟合的方法

答了：决策树剪枝、L2正则和L1正则

8、为什么L1正则可以实现参数稀疏，而L2正则不可以？

答了：L1正则因为是绝对值形式，很多系数被压缩为0,。而L2正则是很多系数被压迫到接近于0，而不是0

9、为什么L1很多系数可以被压缩为0，L2是被压缩至接近于0？

答了：图像上，L1正则是正方形，L2正则是圆形。

L1正则的往往取到正方形顶点，即有很多参数为0
L2正则往往去不到圆形和参数线的交点，即很多分量被压缩到接近于0 

作者：crazyhoney
链接：https://www.nowcoder.com/discuss/32008?type=2&order=0&pos=40&page=3
来源：牛客网

12、python...直接问你个开发中的实际问题吧，如果写的程序跑的非常慢，多方面分析这个问题？

    答了： 1、检查程序是否有多层嵌套循环，优化

    2、检查程序是否有很耗时的操作，看能否优化为多线程并行执行
    3、检查数据量是否非常大，考虑是否可以用分布式计算模型。 


13、SQL中inner join 和outer join的区别？

14、试图给他说说SPARK，结果被严词拒绝（开玩笑的）。。。说时间紧迫，还是他来问吧。。。

15、Kmeans中，现在给你n个样本点不在欧式空间中，无法度量距离。现在给了一个函数F，可以衡量任意两个样本点的相似度。请问Kmeans如何操作？

    答：想了一会，比如K=4的聚类。

    1、首先，随机去4个点，作为初始类簇中心。

    2、计算所有样本点与这4个点的F相似度。根据相似程度，把所有样本点分到4个类中。

    3、在这4个类中，计算每一个样本点 i 到该类其他样本点的相似度和Si。取Si最大的那个点作为这个类的中心。

    4、重复2、3步骤，直到类中心不再变化或者循环次数达到目标。 


5. svm

 （打断）为什么样本点到决策面是 1/||w||

B 手推向量点到决策面的表达式（麻蛋，竟然一时紧张忘了。。。没推出来）

A 点到直线距离公式记得吧？

B 嗯嗯，又没写出来。只能说之前推过，现在一紧张忘了。。。

A 这个也无关紧要，继续

B 继续说SVM


A （打断）知道LR吧，知道LR和SVM有什么不同吗？

B 知道，首先这两个算法的分类思想不同，LR是基于概率推导的，SVM是基于最大化几何间隔的

A （打断）写一下，LR的损失函数

B 手写出来。其实这个sigmoid函数由那个什么族分布（真的忘了名字，其实是：指数族分布），加上二项分布导出来的。损失函数是由最大似然估计求出的。

A 怎么由最大似然估计导出的？推导一下

B 最大似然估计就是求让已知事件发生的概率最大的参数。

假设有5个样本，每一个的类别是yi，由LR计算出的概率是h(x)。那么每一个样本预测正确的概率为：

(H(x)^yi)*((1-h(x))^(1-yi)) ---- 

作者：crazyhoney
链接：https://www.nowcoder.com/discuss/32008?type=2&order=0&pos=40&page=3
来源：牛客网

A 为什么损失函数有个负号？

B 这是因为要应用梯度下降法，引入的。不加负号也可以，梯度上升法。这都是一样的。


A OK，继续，LR和SVM有什么区别？

B SVM决策面只由少量的支持向量决定，而LR的话是所有样本都会参与决策面的更新。

A 对，所以说SVM怎么样？

B SVM对于异常点不敏感，而LR敏感。SVM更加健壮，决策面不受非支持向量影响。

A OK


A 知道过拟合吧？

B 知道，在训练集表现好，在测试集表现一塌糊涂。举个例子就是：学生平时考试成绩非常棒，但一到实际应用就很烂。


A 说说常见的过拟合的解决办法

B 数据，样本不够，如果现在的训练集只是所有样本空间的一个小小的部分，那么这个模型的泛化能力就非常差（边画图，边说）

A 嗯嗯，还有呢

B 可以加正则项，L1，L2正则。L1还可以用来选择特征

A 为什么L1可以用来选择特征

B 因为L1的话会把某些不重要的特征压缩为0

A 为什么L1可以把某些特征压缩为0

B 因为（画图）L1约束是正方形的，经验损失最有可能和L1的正方形的顶点相交，L1比较有棱角。所以可以把某些特征压缩为0


A 还有什么过拟合的解决方法

B 神经网络中，dropout方法。就是每层网络的训练，随机的让一半神经元不工作。达到防止过拟合的目的


A 还有吗？

B 决策树中可以用剪枝操作。


B 决策树过拟合，可以用随机森林。。。

A 什么？？？现在一个决策树已经过拟合了，还要再以它为基准训练随机森林？

B 。。。对，你说的对。我想错了。。。

B 我就知道这些方法了。。。


A OK，挑一个项目给我说说吧

B 说项目（不记得中间有没有再提问了。。。）


B 要不我给您说说spark框架吧，之前还用的挺多。

A 嗯（看简历和笔试题中。。。）

B 开始说。。。说到三分之一


A 好了！ 你不必说了。（大手一挥~）我看你5道笔试题都没写思路，现在把第二题代码写出来

注： 第二题就是检测括号是否匹配

B 我写了啊。。。（给他翻到其中一个的背面）

A 哦，（迅速扫过代码，），为什要把字符压栈呢？不压栈也可以的。

B 是吗？{abc()}这样的也是合法的吗？

A 当然啊（看了一眼题。）

B 好吧，我本来也准备看到字符就丢到，不入栈。但担心这种情况不合法，就给入栈了。


A 嗯，第三题呢？

B 没思路，没写


A 给我说说第四题

第四题：10分钟内，恶意IP访问检测（10分钟内访问次数超过1024即为恶意访问）

B 这是10分钟动态检测的，需要时间刻度精确到秒吗？

A 不需要

B 把10分钟内的<ip,次数>存入hashmap, 再把key,value互换存入treemap。因为treemap是基于key有序的，升序。然后直接拿出来最后一个和1024比较。


A 怎么实现动态的检测，当前检测0-10分钟，那么第11分钟怎么办？

B 把0-10分钟的摘出来，从10分钟内的hashmap中减去，再把10-11分钟内的加上。

我知道这样实现起来，效率应该不高，但这一会我只想到了这个。。。

A 嗯，其实可以这样，把每分钟的分开存储，动态的向后移动，取这10个的总的数据就行。

甚至可以每分钟只存储TOP200的，然后10个分钟的汇总，取TOP1

B 嗯，明白了。


A 说说循环依赖这个怎么解决的？

第五题：系统有很多相互依赖的包，怎么检测循环依赖

B 把它当做一个链表。记录当前的名字在hashset中。如果某一次遍历的依赖名字存在于这个hashet中。就认为有循环依赖。


A 学过数据结构吧？学过图吧？给你一个有向图，怎么检测有环？

B 维护一个访问的数组，记录哪些点被访问过，从一点开始遍历，如果遍历的点被访问过，就说明有环

A 从哪个店开始遍历？

B 从入度为0的点开始遍历

A 如果有多个入度为0的点呢？

B 嗯。。。都要以它为入口开始遍历。

A show me the code!!!

（我内心是崩溃的。。。）

B 纠结了一会，又给他说了一遍思路。


A 嗯，好吧，我没有什么想问的了。你呢？

B 请问您说的这个图的这个应该怎么。。。算了，我还是下去自己看吧。。。我还是想知道怎么解决。。。

A 你说的对啊，就把思路给我讲了一下，和我的差不多。


B 贵公司这里机器学习、深度学习有什么应用场景呢？
A 房屋估价啊什么的。

6. 链家

项目中用到了聚类？手写一下Kmeans 

kd-tree加速


给你出道题写一下，一个文件每一行有3列（\t分隔），每个字符串是abcd，这种形式，中间有大写有小写。

    现认为：abcDe 等于BcaDe （即：不区分大小写，无关顺序）

    要求输出： 字符 空格 出现次数 空格 每一种字符（以|分隔）

    实例输出： abcde 2 abcDe|BcaDe 

一个矩阵都是0,1 且每一行，0都在1前面。求1个数最多的那一行的序号 

7. 美团

1、自我介绍

2、说项目

3、打断，问个扩展题：问答系统，有200W个FAQ，如何用分类模型做分类

思考ing，面试官提示：了解搜索引擎吗？

用倒排索引，把FAQ的问题分词，每个词对应多个FAQ。新来的query分词，每个词对应的FAQ拉出来。再在这个里面做分类。

4、继续说项目

5、说一下hadoop重要的2点

说shuffle，说map、reduce分别分配资源，可以细粒度控制资源占用情况，有利于超大任务平稳正常运行。

6、面试官说，其实是HDFS，正是由于有了分布式文件系统，才可以分布式计算

对，分布式文件系统。数据在哪里计算就在哪里，移动数据变成了移动计算。更高效

7、做题

给定二叉树前序、中序遍历结果。求后序遍历结果

8、一维空间中，2个线段，a1-b1 和a2-b2。判断是否两个线段有交集
他想要的答案是：一个线段里面的大坐标，小于等于另一个线段里面的小坐标。 



2、说项目

3、用RNN了，说一下原理

说RNN，顺便说了长时依赖问题，介绍了LSTM，GRU

4、说情感分析的项目

5、每个句子都被打上标签正向或者负向情感，如果我想得出句子中的每个词的情感倾向，怎么做？

我不清楚该怎么做，就如下扯乎：

认为每个句子的情感倾向由每个词的情感倾向打分相加而得。

有的词正向：+1，+2，+3...

有的词负向：-1，-2，-3...
经过RNN，每一时刻的输出。。。扯完我现在想都想不通了。。。 


6、情感分析里用了SVM，说一下

说SVM，顺便跟LR对比一下

7、还知道其他分类算法吗

嗯嗯，知道，说了决策树，ID3，C4.5，再扯了扯bagging和boosting

8、做题
数轴上从左到右有n各点a[0], a[1], ……,a[n -1]，给定一根长度为L的绳子，求绳子最多能覆盖其中的几个点。要求时间复杂度O(n)，空间复杂度O(1) 


作者：crazyhoney
链接：https://www.nowcoder.com/discuss/32008?type=2&order=0&pos=40&page=3
来源：牛客网

3、场景题：一个景点有很多信息，位置、门票、类型等等。设计一个知识图谱。这个事情如果交给你来做，你会怎么推进

当时就一脸懵逼，只听过这个东西。没研究过。。。就硬着头皮瞎掰

4、我给介绍了SVM

5、你这机器学习这块，只学了这几个月。你认为你有什么优势能跟其他这个专业的人竞争？

麻蛋。。。确实没想过这个问题，继续瞎掰

6、又是场景题：有100亿网页，每个网页都有一个标签。有可能一个标签对应上百万标签，有的标签只对应几个标签。要做一个数据去重，每个标签只要1个网页。

7、工作中遇到了什么实际的难点问题，怎么解决的？

作者：crazyhoney
链接：https://www.nowcoder.com/discuss/32008?type=2&order=0&pos=40&page=3
来源：牛客网

3、用RNN了，说一下原理

4、问RNN怎么训练的？

大概说了说，BPTT。这个不太懂

5、RNN的输入是什么呢？

有word2vec训练的词向量库，一个句子分词后，把词都换成对应的向量输入

6、继续说项目

7、项目用到聚类了？介绍一下

巴拉巴拉巴拉

8、说文本情感分类项目，文本向量用tf-idf这种有什么问题没有？

有，不能捕获到上下文之间的联系。以后尝试用doc2vec这种。

9、了解bagging和boosting吗？

巴拉巴拉

10、做题

1、全排列

2、数组第k大的数

3、数组左减右，求最大差
4、树的路径和 

Trie树

红黑树，

作者：crazyhoney
链接：https://www.nowcoder.com/discuss/32008?type=2&order=0&pos=40&page=3
来源：牛客网

一副扑克牌，未拆封，是有序的排列。要给4个人发牌，要使发的每一张牌的概率相同。

即发第i次牌，发出10和发出2的概率要相等。

B想了想，问了问，说了说思路，谈论了一下。


A排序算法知道哪些

B巴拉巴拉

A快排了解吗？

B说了思想，说了如何划分集合。

A知道快排的非递归实现吗？

B不了解

A那写个mergeSort吧，规定要写代码的。

B一会就搞定了


A咱们问问机器学习吧

A随机森林了解吗？Bagging和boosting了解吗？

B介绍随机森林

A RF的话，如果有一个特征和标签特别强相关。选择划分特征时，如果不随机的从所用特征中随机取一些特征的话，那么每一次那个强相关特征都会被选取。那么每个数都会是一样的。这就是随机森林随机选取一些特征的作用，让某些树，不选这个强相关特征。

B搜嘎。。。

A知道为什么bagging吗？

B。。。

A bootstrap aggregating

B又介绍了boosting


A说说这个项目吧

B巴拉巴拉

A看你项目用了SVM，介绍一下

B巴拉巴拉（中间被打断）

A你们怎么过来说的都很像啊，你们都看什么书？

B。。。我看的周志华的西瓜书和李航的统计学习方法。。。

A继续

B。。。巴拉巴拉

A还用到了RNN，介绍一下
B巴拉巴拉


7. 百度2


算法题：
    1. 两个有序数组求中位数(leetcode)
    2. 判断平衡二叉树(剑指offer)
    3. 最长上升子序列(lintcode)
    4. 二叉树转双向链表(剑指offer)
    5. LRU cache实现(leetcode)
    6. House Robber(leetcode)
    机器学习问题：无非就是树模型(gbdt、xgboost、rf、lightgbm)原理，LR、FM原理，w2v原理，深度学习在推荐系统上应用(和面试官讨论了google的两篇paper，其中wide&deep network讲的时间比较长)，神经网络embedding层和w2v中的embedding的实现区别，其他的记不清了。
    CS基础：进程线程区别，多线程实现方式，线程冲突是什么、怎么解决，TCP三次握手细节，海量数据排序(分治)，其他的不记得。 

L1、L2的区别，L1为什么可以保证稀疏？ 

各种最优化方法比较 拟牛顿法和牛顿法区别，哪个收敛快？为什么？ 


深度学习的优化方法有哪些？ sgd、adam、adgrad区别？ adagrad详细说一下？为什么adagrad适合处理稀疏梯度？

DL常用的激活函数有哪些？

relu和sigmoid有什么区别，优点有哪些？

什么是梯度消失，标准的定义是什么？

DNN的初始化方法有哪些？ 为什么要做初始化？ kaiming初始化方法的过程是怎样的？ 

机器学习算法理论：LR、SVM、树模型、FM/FFM、EM、LDA、word2vec、推荐算法等等，都会被问到，需要懂得算法的推导、适用场景、使用的Trick、分布式实现。

深度学习相关：CNN、RNN、LSTM的基本原理，不同激活函数的差异等等，如果是面的传统机器学习岗的话，DL问的不深，但一定会问。

数据结构与算法：leetcode高频题、lintcode高频题、剑指offer，大概这三样准备好就够了，校招前保证100多道题的积累量，面试时候写code应该就手到擒来了。 


## 资料

### 各种框架学习

https://morvanzhou.github.io

tf： https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/


### Kaggle

https://yq.aliyun.com/articles/71144


### 如何解决机器学习中的数据不平衡问题？ 

https://www.leiphone.com/news/201706/dTRE5ow9qBVLkZSY.html


### XGBoost 与 Boosted Tree

www.52cs.org/?p=429


### Python基础算法/剑指offer

blog.csdn.net/u012505432/article/details/52071537




















